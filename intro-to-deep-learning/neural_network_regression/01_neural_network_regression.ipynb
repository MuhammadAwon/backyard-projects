{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11X8rXihfBELiyBS02oAE8g0KlwwDQtob",
      "authorship_tag": "ABX9TyMfnEaQrt5puYVsDg7A4s6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAwon/backyard-projects/blob/main/intro-to-deep-learning/neural_network_regression/01_neural_network_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkwaBDyfymUJ"
      },
      "source": [
        "# 01. Neural Network Regression with TensorFlow\n",
        "\n",
        "There are many definitions for a [regression problem](https://en.wikipedia.org/wiki/Regression_analysis) but in our case, we're going to simplify it to be: predicting a number.\n",
        "\n",
        "For example, you might want to:\n",
        "- Predict the selling price of houses given information about them (such as number of rooms, size, number of bathrooms).\n",
        "- Predict the coordinates of a bounding box of an item in an image.\n",
        "- Predict the cost of medical insurance for an individual given their demographics (age, sex, gender, race).\n",
        "\n",
        "In this notebook, we're going to set the foundations for how you can take a sample of inputs (this is your data), build a neural network to discover patterns in those inputs and then make a prediction (in the form of a number) based on those inputs.\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "Specifically, we're going to go through doing the following with TensorFlow:\n",
        "- Architecture of a regression model\n",
        "- Input shapes and output shapes\n",
        "  - `X`: features/data (inputs)\n",
        "  - `y`: labels (outputs)\n",
        "- Creating custom data to view and fit\n",
        "- Steps in modelling\n",
        "  - Creating a model\n",
        "  - Compiling a model\n",
        "    - Defining a loss function\n",
        "    - Setting up an optimizer\n",
        "    - Creating evaluation metrics\n",
        "  - Fitting a model (getting it to find patterns in our data)\n",
        "- Evaluating a model\n",
        "  - Visualizng the model\n",
        "  - Looking at training curves\n",
        "  - Compare predictions to ground truth (using our evaluation metrics)\n",
        "- Saving a model (so we can use it later)\n",
        "- Loading a model\n",
        "\n",
        "## How you can use this notebook\n",
        "\n",
        "You can read through the descriptions and the code (it should all run), but there's a better option.\n",
        "\n",
        "Write all of the code yourself.\n",
        "\n",
        "Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n",
        "\n",
        "You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n",
        "\n",
        "Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to **write more code**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nM-kb1hy5Yz"
      },
      "source": [
        "## Typical architecture of a regresison neural network\n",
        "\n",
        "The word *typical* is on purpose.\n",
        "\n",
        "Why?\n",
        "\n",
        "Because there are many different ways (actually, there's almost an infinite number of ways) to write neural networks.\n",
        "\n",
        "But the following is a generic setup for ingesting a collection of numbers, finding patterns in them and then outputing some kind of target number.\n",
        "\n",
        "Yes, the previous sentence is vague but we'll see this in action shortly.\n",
        "\n",
        "| **Hyperparameter** | **Typical value** |\n",
        "| --- | --- |\n",
        "| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |\n",
        "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |\n",
        "| Neurons per hidden layer | Problem specific, generally 10 to 100 |\n",
        "| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |\n",
        "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |\n",
        "| Output activation | None, ReLU, logistic/tanh |\n",
        "| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |\n",
        "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |\n",
        "\n",
        "***Table 1:*** *Typical architecture of a regression network.* ***Source:*** *Adapted from page 293 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by AurÃ©lien GÃ©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n",
        "\n",
        "Again, if you're new to neural networks and deep learning in general, much of the above table won't make sense. But don't worry, we'll be getting hands-on with all of it soon.\n",
        "\n",
        "> ðŸ”‘ **Note:** A **hyperparameter** in machine learning is something a data analyst or developer can set themselves, where as a **parameter** usually describes something a model learns on its own (a value not explicitly set by an analyst).\n",
        "\n",
        "To use TensorFlow, we'll import it as the common alias `tf` (short for TensorFlow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-PESaZStiDr",
        "outputId": "c9e6ef5f-b4e4-42ef-83e1-098cebae4342"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import TensorFlow and its version (version should be 2.x+)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtRtLYk2zVRZ"
      },
      "source": [
        "## Regression input shapes and output shapes\n",
        "\n",
        "One of the most important concepts when working with neural networks are the input and output shapes.\n",
        "\n",
        "The **input shape** is the shape of your data that goes into the model.\n",
        "\n",
        "The **output shape** is the shape of your data you want to come out of your model.\n",
        "\n",
        "These will differ depending on the problem you're working on.\n",
        "\n",
        "Neural networks accept input numbers and output numbers. These numbers are typically represented as tensors (or arrays).\n",
        "\n",
        "Before, we created data using NumPy arrays, but we could do the same with tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i1wKWqfxEHx",
        "outputId": "3f0e11bd-5d2b-4e42-8767-4da95dfe3a67"
      },
      "source": [
        "# Example input and output shapes of a regression model\n",
        "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z023zllDzm0d",
        "outputId": "b1037562-79d3-4847-f83e-15ceb0bdb707"
      },
      "source": [
        "# Input and output shape\n",
        "house_info.shape, house_price.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([3]), TensorShape([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "KQv2aBTburd7",
        "outputId": "c7c91ef1-c61c-4747-b62f-2b58cc153bd2"
      },
      "source": [
        "# Create features (using tensors)\n",
        "X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels (using tensors)\n",
        "y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umiUaP950Gdn"
      },
      "source": [
        "Our goal here will be to use `X` to predict `y`.\n",
        "\n",
        "So our **input** will be `X` and our **output** will be `y`.\n",
        "\n",
        "Knowing this, what do you think our input and output shapes will be?\n",
        "\n",
        "Let's take a look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA4TSEK6xrcA",
        "outputId": "5851bf81-7930-452a-b643-da231832d757"
      },
      "source": [
        "# Take a single example of X\n",
        "input_shape = X[0].shape\n",
        "\n",
        "# Take a single example of y\n",
        "output_shape = y[0].shape\n",
        "\n",
        "input_shape, output_shape  # these are both scalars (no shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHqWT_Hd0n6g"
      },
      "source": [
        "From this it seems our inputs and outputs have no shape?\n",
        "\n",
        "It's because no matter what kind of data we pass to our model, it's always going to take as input and return as ouput some kind of tensor.\n",
        "\n",
        "But in our case because of our dataset (only 2 small lists of numbers), we're looking at a special kind of tensor, more specificially a rank 0 tensor or a scalar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7ySOTLlPWqk",
        "outputId": "19c3ba42-593b-44e6-ec06-307e4bebb3ac"
      },
      "source": [
        "# Let's take a look at the single examples individually\n",
        "X[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydZy8YgWPUuS"
      },
      "source": [
        "In our case, we're trying to build a model to predict the pattern between `X[0]` equalling `-7.0` and `y[0]` equalling `3.0`.\n",
        "\n",
        "So now we get our answer, we're trying to use 1 `X` value to predict 1 `y` value.\n",
        "\n",
        "You might be thinking, \"this seems pretty complicated for just predicting a straight line...\".\n",
        "\n",
        "And you'd be right.\n",
        "\n",
        "But the concepts we're covering here, the concepts of input and output shapes to a model are fundamental. \n",
        "\n",
        "In fact, they're probably two of the things you'll spend the most time on when you work with neural networks: **making sure your input and outputs are in the correct shape**.\n",
        "\n",
        "If it doesn't make sense now, we'll see plenty more examples later on (soon you'll notice the input and output shapes can be almost anything you can imagine).\n",
        "\n",
        "![example of input and output shapes for a housing price prediction problem](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png)\n",
        "*If you were working on building a machine learning algorithm for predicting housing prices, your inputs may be number of bedrooms, number of bathrooms and number of garages, giving you an input shape of 3 (3 different features). And since you're trying to predict the price of the house, your output shape would be 1.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSmD13-7Qvmz"
      },
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "Now we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n",
        "\n",
        "In TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n",
        "\n",
        "1. **Creating a model** - piece together the layers of a neural network yourself (using the [Functional](https://www.tensorflow.org/guide/keras/functional) or [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)) or import a previously built model (known as transfer learning).\n",
        "2. **Compiling a model** - defining how a models performance should be measured (loss/metrics) as well as defining how it should improve (optimizer). \n",
        "3. **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`). \n",
        "\n",
        "Let's see these in action using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) to build a model for our regression data. And then we'll step through each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CziOsMpgx9j9",
        "outputId": "e6bcf1a8-1446-4f5a-dd39-aa572a586b0b"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,  # mas is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(),  # SGD is short for stochastic gradient descent\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcffcd5e10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZD15ZkHRXCT"
      },
      "source": [
        "We've just trained a model to figure out the patterns between `X` and `y`.\n",
        "\n",
        "How do you think it went?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBRFywWPN5_B",
        "outputId": "4ade6a39-9f0c-4c5d-fb33-70e178182571"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLbpY6V6RcTG"
      },
      "source": [
        "What do you think the outcome should be if we passed our model an `X` value of 17.0?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMa6hAjvOr2G",
        "outputId": "5bc06d00-6843-4e62-b17f-a35d6df34a24"
      },
      "source": [
        "# Make a prediction with the model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbzq3sOrRjjO"
      },
      "source": [
        "It doesn't go very well... it should've output something close to 27.0.\n",
        "\n",
        "> ðŸ¤” **Question:** What's Keras? I thought we were working with TensorFlow but every time we write TensorFlow code, `keras` comes after `tf` (e.g. `tf.keras.layers.Dense()`)?\n",
        "\n",
        "Before TensorFlow 2.0+, [Keras](https://keras.io/) was an API designed to be able to build deep learning models with ease. Since TensorFlow 2.0+, its functionality has been tightly integrated within the TensorFlow library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7pybbsTRxCD"
      },
      "source": [
        "## Improving a model\n",
        "\n",
        "How do you think you'd improve upon our current model?\n",
        "\n",
        "If you guessed by tweaking some of the things we did above, you'd be correct.\n",
        "\n",
        "To improve our model, we alter almost every part of the 3 steps we went through before.\n",
        "\n",
        "1. **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
        "2. **Compiling a model** - you might want to choose optimization function or perhaps change the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - perhaps you could fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from).\n",
        "\n",
        "![various options you can use to improve a neural network model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-improving-a-model-from-model-perspective.png)\n",
        "*There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) and the practice of trying to find the best hyperparameters is referred to as [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization).*\n",
        "\n",
        "We just introduced a bunch of possible steps. The important thing to remember is how you alter each of these will depend on the problem you're working on.\n",
        "\n",
        "And the good thing is, over the next few problems, we'll get hands-on with all of them.\n",
        "\n",
        "For now, let's keep it simple, all we'll do is train our model for longer (everything else will stay the same)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfSOS1b3O2KJ",
        "outputId": "75050cbe-e206-400a-b409-c9f927a3fe1e"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8423 - mae: 10.8423\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7098 - mae: 10.7098\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.5773 - mae: 10.5773\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.4448 - mae: 10.4448\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.3123 - mae: 10.3123\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1798 - mae: 10.1798\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0473 - mae: 10.0473\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.9148 - mae: 9.9148\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7823 - mae: 9.7823\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.6498 - mae: 9.6498\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5173 - mae: 9.5173\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.3848 - mae: 9.3848\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2523 - mae: 9.2523\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1198 - mae: 9.1198\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9873 - mae: 8.9873\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8548 - mae: 8.8548\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7223 - mae: 8.7223\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5898 - mae: 8.5898\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4573 - mae: 8.4573\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3248 - mae: 8.3248\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.1923 - mae: 8.1923\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0598 - mae: 8.0598\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9273 - mae: 7.9273\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7948 - mae: 7.7948\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6623 - mae: 7.6623\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5298 - mae: 7.5298\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3973 - mae: 7.3973\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2648 - mae: 7.2648\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1963 - mae: 7.1963\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1738 - mae: 7.1738\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8813 - mae: 6.8813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcfe418850>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR0WNSfVZjYE",
        "outputId": "5b3128ee-2fa8-40b0-e4d0-5e26154cdb2d"
      },
      "source": [
        "# Remind ourselves of what X and y are\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgHoEtqFZ7oh",
        "outputId": "8976762b-ce45-4800-efa2-416c8287252e"
      },
      "source": [
        "# Try and predict what y would be if X was 17.0\n",
        "model.predict([17.0])  # the right answer is 27.0 (y = X + 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.158512]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndObiabOfyFc"
      },
      "source": [
        "Let's do another experiment and try to improve our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV9BMMB7bnBO",
        "outputId": "81a7f2d6-2ef4-47f1-8b9c-dbb239a10e22"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model (add 1 hidden layer of 50 nodes)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(50),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model (change optimizer to Adam(lr=0.01))\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 13.1820 - mae: 13.1820\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.5071 - mae: 12.5071\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.8279 - mae: 11.8279\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.1425 - mae: 11.1425\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.4485 - mae: 10.4485\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7427 - mae: 9.7427\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.0218 - mae: 9.0218\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.2826 - mae: 8.2826\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5221 - mae: 7.5221\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7841 - mae: 6.7841\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7505 - mae: 6.7505\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0302 - mae: 7.0302\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1931 - mae: 7.1931\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2735 - mae: 7.2735\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2165 - mae: 7.2165\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0282 - mae: 7.0282\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8275 - mae: 6.8275\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5956 - mae: 6.5956\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3389 - mae: 6.3389\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0742 - mae: 6.0742\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0195 - mae: 6.0195\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9610 - mae: 5.9610\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.0150 - mae: 6.0150\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0147 - mae: 6.0147\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9085 - mae: 5.9085\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7090 - mae: 5.7090\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5382 - mae: 5.5382\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4295 - mae: 5.4295\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3177 - mae: 5.3177\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3173 - mae: 5.3173\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2878 - mae: 5.2878\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.2103 - mae: 5.2103\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0890 - mae: 5.0890\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9280 - mae: 4.9280\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7312 - mae: 4.7312\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6041 - mae: 4.6041\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5056 - mae: 4.5056\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4017 - mae: 4.4017\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2958 - mae: 4.2958\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.1313 - mae: 4.1313\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9818 - mae: 3.9818\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8253 - mae: 3.8253\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6671 - mae: 3.6671\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5365 - mae: 3.5365\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3534 - mae: 3.3534\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1903 - mae: 3.1903\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0254 - mae: 3.0254\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8499 - mae: 2.8499\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6844 - mae: 2.6844\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4541 - mae: 2.4541\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2346 - mae: 2.2346\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0468 - mae: 2.0468\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8348 - mae: 1.8348\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5549 - mae: 1.5549\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3570 - mae: 1.3570\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1130 - mae: 1.1130\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8263 - mae: 0.8263\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6080 - mae: 0.6080\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2654 - mae: 0.2654\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3319 - mae: 0.3319\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5022 - mae: 0.5022\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6316 - mae: 0.6316\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7575 - mae: 0.7575\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6993 - mae: 0.6993\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8384 - mae: 0.8384\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8231 - mae: 0.8231\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6088 - mae: 0.6088\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6624 - mae: 0.6624\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6882 - mae: 0.6882\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4096 - mae: 0.4096\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2376 - mae: 0.2376\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4573 - mae: 0.4573\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3699 - mae: 0.3699\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3439 - mae: 0.3439\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5023 - mae: 0.5023\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4859 - mae: 0.4859\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3219 - mae: 0.3219\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3975 - mae: 0.3975\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3645 - mae: 0.3645\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1428 - mae: 0.1428\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0749 - mae: 0.0749\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1437 - mae: 0.1437\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1804 - mae: 0.1804\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3013 - mae: 0.3013\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2711 - mae: 0.2711\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2547 - mae: 0.2547\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2350 - mae: 0.2350\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0871 - mae: 0.0871\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0687 - mae: 0.0687\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2191 - mae: 0.2191\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2195 - mae: 0.2195\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2530 - mae: 0.2530\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2993 - mae: 0.2993\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1965 - mae: 0.1965\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2204 - mae: 0.2204\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1981 - mae: 0.1981\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1086 - mae: 0.1086\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1370 - mae: 0.1370\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1814 - mae: 0.1814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcffc17f10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI83uCw-dllO",
        "outputId": "492e6d6c-7c4f-4fc1-b453-8b84900874aa"
      },
      "source": [
        "# Let's remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BytW7A9tdcdf",
        "outputId": "bdbc9f17-690d-4a6e-fefc-c7d73227d027"
      },
      "source": [
        "# Make a prediction\n",
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.216782]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znb0NPKXbxqJ"
      },
      "source": [
        "Much better! \n",
        "\n",
        "Now we've trained a model, how could we evaluate it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDf9kIM4b4Fr"
      },
      "source": [
        "## Evaluating a model \n",
        "\n",
        "A typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> evaluate it -> build (tweak) a model -> evaulate it -> build (tweak) a model -> evaluate it...\n",
        "```\n",
        "\n",
        "The tweaking comes from maybe not building a model from scratch but adjusting an existing one.\n",
        "\n",
        "### Visualize, visualize, visualize\n",
        "\n",
        "When it comes to evaluation, you'll want to remember the words: \"visualize, visualize, visualize.\" \n",
        "\n",
        "This is because you're probably better looking at something (doing) than you are thinking about something.\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* **The data** - what data are you working with? What does it look like?\n",
        "* **The model itself** - what does the architecture look like? What are the different shapes?\n",
        "* **The training of a model** - how does a model perform while it learns?\n",
        "* **The predictions of a model** - how do the predictions of a model line up against the ground truth (the original labels)?\n",
        "\n",
        "Let's start by visualizing the model.\n",
        "\n",
        "But first, we'll create a little bit of a bigger dataset and a new model we can use (it'll be the same as before, but the more practice the better)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4woSbRIFd3lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b5e150-91f5-4757-fd36-b47ae6019577"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = np.arange(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lxl0XPxml06",
        "outputId": "e45dff8a-a524-405c-9775-dab501d43eeb"
      },
      "source": [
        "# Make labels for the dataset (adhering to the same pattern as before)\n",
        "y = np.arange(-90, 110, 4)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDlYH2dHmazq"
      },
      "source": [
        "Since $y=X+10$, we could make the labels like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd-KHYOdlf6Z",
        "outputId": "a3e57805-1a35-48a6-a34f-e7d0c744a476"
      },
      "source": [
        "# Same result as above\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IG27mZWnU22"
      },
      "source": [
        "## Split data into training/test set\n",
        "\n",
        "One of the other most common and important steps in a machine learning project is creating a training and test set (and when required, a validation set).\n",
        "\n",
        "Each set serves a specific purpose:\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data available (like the course materials you study during the semester).\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the total data available (like the practice exam you take before the final exam).\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned, it's typically 10-15% of the total data available (like the final exam you take at the end of the semester).\n",
        "\n",
        "For now, we'll just use a training and test set, this means we'll have a dataset for our model to learn on as well as be evaluated on.\n",
        "\n",
        "We can create them by splitting our `X` and `y` arrays.\n",
        "\n",
        "> ðŸ”‘ **Note:** When dealing with real-world data, this step is typically done right at the start of a project (the test set should always be kept separate from all other data). We want our model to learn on training data and then evaluate it on test data to get an indication of how well it **generalizes** to unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV313X-pl-JV",
        "outputId": "c6bed0c0-83ca-4238-c505-18b3ae5e465b"
      },
      "source": [
        "# Check how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE91v368psOo",
        "outputId": "f885f26a-96ca-4577-e327-85ddec760426"
      },
      "source": [
        "# Split data into train and test sets\n",
        "X_train = X[:40]  # first 40 examples (80% of data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:]  # last 10 examples (20% of data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIVNZU0BrsEJ"
      },
      "source": [
        "## Visualizing the data\n",
        "\n",
        "Now we've got our training and test data, it's a good idea to visualize it.\n",
        "\n",
        "Let's plot it with some nice colours to differentiate what's what."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "0XC0-dg7qWKQ",
        "outputId": "2309516a-8102-4c1a-ae93-9c6818d2bbeb"
      },
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c='b', label='Training data')\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c='g', label='Testing data')\n",
        "# Show the legend\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEefNdLFr5OC"
      },
      "source": [
        "Any time you can visualize your data, your model, your anything, it's a good idea. \n",
        "\n",
        "With this graph in mind, what we'll be trying to do is build a model which learns the pattern in the blue dots (`X_train`) to draw the green dots (`X_test`).\n",
        "\n",
        "Time to build a model. We'll make the exact same one from before (the one we trained for longer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M17rugnfrDMS"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Fit the model (same as above)\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkhIOegydGC"
      },
      "source": [
        "## Visualizing the model\n",
        "\n",
        "After you've built a model, you might want to take a look at it (especially if you haven't built many before).\n",
        "\n",
        "You can take a look at the layers and shapes of your model by calling [`summary()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary) on it.\n",
        "\n",
        "> ðŸ”‘ **Note:** Visualizing a model is particularly helpful when you run into input and output shape mismatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyBt7TSSuvGU",
        "outputId": "36b41eef-3648-430d-ae12-5e414923440e"
      },
      "source": [
        "# Doesn't work (model not fit/built)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_one\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taCBLpr1ysRc"
      },
      "source": [
        "The cell above errors because we haven't fit or built our model.\n",
        "\n",
        "We also haven't told it what input shape it should be expecting.\n",
        "\n",
        "Remember above, how we discussed the input shape was just one number?\n",
        "\n",
        "We can let our model know the input shape of our data using the `input_shape` parameter to the first layer (usually if `input_shape` isn't defined, Keras tries to figure it out automatically)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6DQgM4xu2kn"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as above)\n",
        "model = tf.keras.Sequential([ # define the input_shape to our model\n",
        "                             tf.keras.layers.Dense(10, input_shape=[1], name='input_layer'),\n",
        "                             tf.keras.layers.Dense(1, name='output_layer')\n",
        "], name='model_one')\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hDjJypJvqGC",
        "outputId": "a1984144-482f-40a3-a8cf-a18256592bdb"
      },
      "source": [
        "# This will work after specifying the input shape\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_one\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEwG5LfYzMYw"
      },
      "source": [
        "Calling `summary()` on our model shows us the layers it contains, the output shape and the number of parameters.\n",
        "* **Total params** - total number of parameters in the model.\n",
        "* **Trainable parameters** - these are the parameters (patterns) the model can update as it trains.\n",
        "* **Non-trainable parameters** - these parameters aren't updated during training (this is typical when you bring in the already learned patterns from other models during transfer learning).\n",
        "\n",
        "> ðŸ“– **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out [MIT's introduction to deep learning video](https://youtu.be/njKP3FqW3Sk).\n",
        "\n",
        "> ðŸ›  **Exercise:** Try playing around with the number of hidden units in the `Dense` layer (e.g. `Dense(2)`, `Dense(3)`). How does this change the Total/Trainable params? Investigate what's causing the change.\n",
        "\n",
        "For now, all you need to think about these parameters is that their learnable patterns in the data.\n",
        "\n",
        "Let's fit our model to the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBwQFzecvrif",
        "outputId": "a8257db6-ef0c-456b-fe9f-1c5a2d80356b"
      },
      "source": [
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)  # verbose controls the output results to display "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcffafa850>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFgRBkrOxz2s",
        "outputId": "fcd47eff-654e-47c9-a0cc-67680e53547f"
      },
      "source": [
        "# Check the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_one\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrIMZW3U52fC"
      },
      "source": [
        "Alongside summary, you can also view a 2D plot of the model using [`plot_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "WjrVLTCm2w9Q",
        "outputId": "ade6d304-64a2-4b7b-a85c-e7e9515dbe10"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPK5b0258p8"
      },
      "source": [
        "In our case, the model we used only has an input and an output but visualizing more complicated models can be very helpful for debugging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0uXZaeE5_PP"
      },
      "source": [
        "## Visualizing the predictions\n",
        "\n",
        "Now we've got a trained model, let's visualize some predictions.\n",
        "\n",
        "To visualize predictions, it's always a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` vs. `y_pred` (ground truth vs. predictions).\n",
        "\n",
        "First, we'll make some predictions on the test data (`X_test`), remember the model has never seen the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxYpElEV3Wdl",
        "outputId": "58507bdf-82df-4759-c235-32f28f1184d0"
      },
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "# View the predictions\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R52miCBW-gv5"
      },
      "source": [
        "Okay, we get a list of numbers but how do these compare to the ground truth labels?\n",
        "\n",
        "Let's build a plotting function to find out.\n",
        "\n",
        "> ðŸ”‘ **Note:** If you think you're going to be visualizing something a lot, it's a good idea to functionize it so you can use it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf-XVfkd76dG"
      },
      "source": [
        "# Define funtion to plot model predictions\n",
        "def plot_predictions(train_data=X_train, train_labels=y_train,\n",
        "                     test_data=X_test, test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth labels.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c='b', label='Training data')\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c='g', label='Test data')\n",
        "  # Plot the predictions in red\n",
        "  plt.scatter(test_data, predictions, c='r', label='Predictions')\n",
        "  # Show the legend\n",
        "  plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "w70j0ELu9Tlv",
        "outputId": "357d2964-a285-4e5b-ce43-eb242b9f175c"
      },
      "source": [
        "plot_predictions(train_data=X_train, train_labels=y_train,\n",
        "                 test_data=X_test, test_labels=y_test,\n",
        "                 predictions=y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mHjDrvC-30O"
      },
      "source": [
        "From the plot we can see our predictions aren't totally outlandish but they definitely aren't anything special either."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riZ-fs4u-9QQ"
      },
      "source": [
        "## Evaluating predictions\n",
        "\n",
        "Alongside visualizations, evaulation metrics are your alternative best option for evaluating your model.\n",
        "\n",
        "Depending on the problem you're working on, different models have different evaluation metrics. \n",
        "\n",
        "Three of the main metrics used for regression problems are:\n",
        "* **Mean absolute error (MAE)** - the mean difference between each of the predictions.\n",
        "* **Mean squared error (MSE)** - the squared mean difference between of the predictions (use if larger errors are more detrimental than smaller errors).\n",
        "* **Huber** - combination of MAE and MSE, it is less sensitive to outliers than MSE.\n",
        "\n",
        "The lower each of these values, the better.\n",
        "\n",
        "You can also use [`model.evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) which will return the loss of the model as well as any metrics setup during the compile step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQIYz1an9Zlu",
        "outputId": "a49384d4-4f51-436d-bc24-34971ec43a1a"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 144ms/step - loss: 3.1969 - mae: 3.1969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196942090988159, 3.196942090988159]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oztw7zwJDKhK"
      },
      "source": [
        "In our case, since we used MAE for the loss function as well as MAE for the metrics, `model.evaulate()` returns them both.\n",
        "\n",
        "TensorFlow also has built in functions for MSE and MAE.\n",
        "\n",
        "For many evaluation functions, the premise is the same: compare predictions to the ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXYQQp-vCOwC",
        "outputId": "22659fa7-eef8-4a96-a393-fd61dfae942d"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1-9ae23GIBl"
      },
      "source": [
        "That's strange, MAE should be a single output.\n",
        "\n",
        "Instead, we get 10 values.\n",
        "\n",
        "This is because our `y_test` and `y_pred` tensors are different shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duo7U9qpE2CH",
        "outputId": "d154c876-f92d-42d6-86b9-392f0049df90"
      },
      "source": [
        "# Check the test label tensor values\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHKUk8OsCfGJ",
        "outputId": "023be660-894d-4f5d-b8ee-9f454876d4fe"
      },
      "source": [
        "# Check the predictions tensor values (notice the extra square brackets)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA17XJmEE4MA",
        "outputId": "8a0b8f8e-9853-4c0d-a76e-b1bc8f899e6a"
      },
      "source": [
        "# Check the tensor shapes\n",
        "y_test.shape, y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10,), (10, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj2VCmUnGqdc"
      },
      "source": [
        "Remember how we discussed dealing with different input and output shapes is one the most common issues you'll come across, this is one of those times.\n",
        "\n",
        "But not to worry.\n",
        "\n",
        "We can fix it using [`squeeze()`](https://www.tensorflow.org/api_docs/python/tf/squeeze), it'll remove the the `1` dimension from our `y_pred` tensor, making it the same shape as `y_test`.\n",
        "\n",
        "> ðŸ”‘ **Note:** If you're comparing two tensors, it's important to make sure they're the right shape(s) (you won't always have to manipulate the shapes, but always be on the look out, *many* errors are the result of mismatched tensors, especially mismatched input and output shapes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzDX-MgUGxpI",
        "outputId": "ce6aade1-4624-4516-d279-78bc47b0ab05"
      },
      "source": [
        "# Shape before squeeze()\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJLCKE8TG3IB",
        "outputId": "e5d8cf6b-099f-42bb-f1f4-8113a75f69ac"
      },
      "source": [
        "# Shape after squeeze()\n",
        "y_pred.squeeze().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRsWG7zIHDSN",
        "outputId": "b3ae2f73-80d7-4bb0-cffc-09428d93cc01"
      },
      "source": [
        "# What do they look like?\n",
        "y_test, y_pred.squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106]),\n",
              " array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
              "         93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWZ_zAUkHOBr"
      },
      "source": [
        "Okay, now we know how to make our `y_test` and `y_pred` tenors the same shape, let's use our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Dw9TMLFZRw",
        "outputId": "34373a09-d64e-4f28-9ce9-35d8d183ae91"
      },
      "source": [
        "# Calculate the MAE\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXZDAN1Fk8o",
        "outputId": "5242bf0d-3f46-4d16-c44a-aeba51f2fbc0"
      },
      "source": [
        "# Calculate the MSE\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
        "mse.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.070143"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdlHPjAwL5z6"
      },
      "source": [
        "We can also calculate the MAE using pure TensorFlow functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv3nRod3MCyV",
        "outputId": "4ff097bf-04ee-47f5-d38d-7e488e426432"
      },
      "source": [
        "# Returns the same as tf.metrics.mean_absolute_error()\n",
        "tf.reduce_mean(tf.abs(y_test - y_pred.squeeze()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=3.196940612792969>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQXmcI99MUXG"
      },
      "source": [
        "Again, it's a good idea to functionize anything you think you might use over again (or find yourself using over and over again).\n",
        "\n",
        "Let's make functions for our evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHs_wY5CF4ck"
      },
      "source": [
        "# Create function for MAE\n",
        "def mae(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates mean absolute error between y_test and y_pred.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                        y_pred=tf.squeeze(y_pred)).numpy()\n",
        "\n",
        "# Create function for MSE\n",
        "def mse(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates mean squared error between y_test and y_pred.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred)).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmx15uUfmkpu"
      },
      "source": [
        "## Running experiments to improve a model\n",
        "\n",
        "After seeing the evaluation metrics and the predictions your model makes, it's likely you'll want to improve it.\n",
        "\n",
        "Again, there are many different ways you can do this, but 3 of the main ones are:\n",
        "1. **Get more data** - get more examples for your model to train on (more opportunities to learn patterns).\n",
        "2. **Make your model larger (use a more complex model)** - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. **Train for longer** - give your model more of a chance to find the patterns in the data.\n",
        "\n",
        "Since we created our dataset, we could easily make more data but this isn't always the case when you're working with real-world datasets.\n",
        "\n",
        "So let's take a look at how we can improve our model using 2 and 3.\n",
        "\n",
        "To do so, we'll build 3 models and compare their results:\n",
        "1. `model_1` - same as original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs.\n",
        "3. `model_3` - 2 layers, trained for 500 epochs.\n",
        "\n",
        "**Build `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiP7oP7pjIOw",
        "outputId": "b49beb4c-a7ce-4935-83b7-f73867721204"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate original model\n",
        "model_1 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcffa13550>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "SFpVH0b-kDBP",
        "outputId": "02136b00-bb68-4c38-c749-53a7a6aff929"
      },
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbcfeb26710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fxv19SUlN8h",
        "outputId": "e6849660-4a1a-45a1-ce2e-8005b611a023"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "mae_1, mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18.745327, 353.57336)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKsqkJtQm5Un"
      },
      "source": [
        "**Build `model_2`**\n",
        "\n",
        "This time we'll add an extra dense layer (so now our model will have 2 layers) whilst keeping everything else the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqBfsqpUlnYC",
        "outputId": "f7b1fe41-7c8e-449a-ef99-b0d7e15b4a2b"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_1 and add an extra layer\n",
        "model_2 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(10),\n",
        "                               tf.keras.layers.Dense(1)  # add a second layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mse'])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4058 - mse: 1084.1482\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.6339 - mse: 777.9203\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.8935 - mse: 1334.8956\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.4055 - mse: 1106.8035\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9463 - mse: 281.1077\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.8819 - mse: 168.6621\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1988 - mse: 151.3509\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0910 - mse: 160.3745\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 40.4763 - mse: 2586.0090\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.8688 - mse: 1094.4382\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2473 - mse: 147.9359\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2803 - mse: 890.3866\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 16.9897 - mse: 399.9678\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9217 - mse: 1049.5515\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.9948 - mse: 450.2580\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.3510 - mse: 80.6206\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.8636 - mse: 174.7868\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.5304 - mse: 565.8053\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3469 - mse: 167.7749\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.6985 - mse: 455.7096\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8984 - mse: 347.1929\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1991 - mse: 285.1767\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.7720 - mse: 91.7852\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mse: 153.7430\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6838 - mse: 233.2949\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.1877 - mse: 1024.6091\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7432 - mse: 194.8454\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.8730 - mse: 835.6074\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mse: 96.7786\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.2641 - mse: 1535.1349\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 53.0225 - mse: 5030.2988\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9951 - mse: 211.7025\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.6357 - mse: 337.3666\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6925 - mse: 214.4824\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mse: 92.9126\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6497 - mse: 403.6573\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0382 - mse: 192.3919\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mse: 433.6717\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.1013 - mse: 529.6439\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mse: 610.1324\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9102 - mse: 279.6183\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2809 - mse: 186.6180\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7333 - mse: 167.0952\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mse: 830.4244\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3897 - mse: 128.9549\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7904 - mse: 181.9212\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6438 - mse: 153.8708\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.2335 - mse: 402.8494\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5729 - mse: 99.8337\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.8185 - mse: 260.3670\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mse: 154.7956\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.5538 - mse: 1613.0886\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mse: 302.5293\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9713 - mse: 859.3983\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.1938 - mse: 805.5452\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8837 - mse: 170.9834\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7445 - mse: 198.7015\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5995 - mse: 102.5890\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5172 - mse: 216.3367\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mse: 208.6371\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4604 - mse: 428.6393\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6052 - mse: 136.9777\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mse: 152.4555\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8450 - mse: 911.7512\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6761 - mse: 142.7374\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.7809 - mse: 704.4492\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7136 - mse: 136.0194\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6397 - mse: 149.2300\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.6914 - mse: 742.1761\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3316 - mse: 166.1628\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4355 - mse: 323.0843\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.7437 - mse: 67.0210\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mse: 183.7296\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0400 - mse: 908.8992\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5896 - mse: 149.3948\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4371 - mse: 188.3310\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6489 - mse: 429.2708\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0614 - mse: 95.4870\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9675 - mse: 864.0864\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.7463 - mse: 1104.4032\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6714 - mse: 170.7055\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0228 - mse: 211.9191\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4218 - mse: 395.5589\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mse: 73.0935\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9650 - mse: 312.8361\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mse: 315.3605\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1086 - mse: 521.2534\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.8229 - mse: 1287.1907\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1742 - mse: 124.1342\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.5240 - mse: 663.8611\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5716 - mse: 161.7467\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3977 - mse: 464.1326\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 7.4138 - mse: 81.9820\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7380 - mse: 445.7379\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1144 - mse: 164.0820\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 19.4346 - mse: 510.5842\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.1593 - mse: 209.9755\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 11.5653 - mse: 169.4052\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.8827 - mse: 265.4630\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.2277 - mse: 608.8218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd56372f90>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "99AbBy9To_gm",
        "outputId": "8efb02e6-fa17-4e78-ec4b-e7c109f49f84"
      },
      "source": [
        "# Make and plot predictions for model_2\n",
        "y_pred_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_pred_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd562c0b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTBM85blpPo6",
        "outputId": "036918c9-db11-4849-f8f3-31f14e26acae"
      },
      "source": [
        "# Calculate model_2 metrics\n",
        "mae_2 = mae(y_test, y_pred_2)\n",
        "mse_2 = mse(y_test, y_pred_2)\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.1969407, 13.070143)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rkAIHOvMkU"
      },
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "For our 3rd model, we'll keep everything the same as `model_2` except this time we'll train for longer (500 epochs instead of 100).\n",
        "\n",
        "This will give our model more of a chance to learn the patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y3UXTuJpidO",
        "outputId": "eb140b51-a820-4b34-e8bd-ceaf73f79aa6"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Replicate model_2\n",
        "model_3 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(10),\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae'])\n",
        "\n",
        "# Fit the model (this time for 500 epochs, not 100)\n",
        "model_3.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2277 - mae: 20.2277\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4479 - mae: 11.4479\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4842 - mae: 17.4842\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0217 - mae: 7.0217\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.5789 - mae: 23.5789\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.8932 - mae: 16.8932\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2954 - mae: 9.2954\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.3749 - mae: 25.3749\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.4621 - mae: 13.4621\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5238 - mae: 9.5238\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5987 - mae: 14.5987\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5670 - mae: 9.5670\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8092 - mae: 17.8092\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1782 - mae: 17.1782\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1182 - mae: 11.1182\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.3071 - mae: 23.3071\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.6144 - mae: 9.6144\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6899 - mae: 10.6899\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0355 - mae: 8.0355\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.6859 - mae: 29.6859\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0714 - mae: 8.0714\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.3086 - mae: 28.3086\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.9014 - mae: 32.9014\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.6291 - mae: 19.6291\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0095 - mae: 7.0095\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.8056 - mae: 21.8056\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.9812 - mae: 7.9812\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.0585 - mae: 21.0585\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0107 - mae: 9.0107\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.0502 - mae: 24.0502\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7537 - mae: 9.7537\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.3052 - mae: 18.3052\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.5833 - mae: 7.5833\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.5755 - mae: 18.5755\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5360 - mae: 10.5360\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.2694 - mae: 18.2694\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1658 - mae: 23.1658\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1362 - mae: 9.1362\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9181 - mae: 8.9181\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4732 - mae: 16.4732\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4208 - mae: 8.4208\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 36.9540 - mae: 36.9540\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.5820 - mae: 25.5820\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5392 - mae: 9.5392\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.6058 - mae: 26.6058\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7248 - mae: 8.7248\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.6172 - mae: 15.6172\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.3065 - mae: 18.3065\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1994 - mae: 8.1994\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4964 - mae: 7.4964\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3374 - mae: 18.3374\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2895 - mae: 10.2895\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.6425 - mae: 29.6425\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.5556 - mae: 10.5556\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4537 - mae: 15.4537\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.0174 - mae: 17.0174\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.8218 - mae: 32.8218\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7038 - mae: 10.7038\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9054 - mae: 8.9054\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.1321 - mae: 22.1321\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7113 - mae: 11.7113\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.5734 - mae: 21.5734\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.2485 - mae: 19.2485\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0156 - mae: 11.0156\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6187 - mae: 9.6187\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.5908 - mae: 21.5908\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.2851 - mae: 26.2851\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.8525 - mae: 9.8525\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.5630 - mae: 22.5630\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 10.1499 - mae: 10.1499\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 18.0464 - mae: 18.0464\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.8377 - mae: 28.8377\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.5279 - mae: 16.5279\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2115 - mae: 11.2115\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.5839 - mae: 27.5839\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.2680 - mae: 8.2680\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2580 - mae: 9.2580\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.1440 - mae: 18.1440\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5995 - mae: 10.5995\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.8992 - mae: 7.8992\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4015 - mae: 17.4015\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0089 - mae: 11.0089\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7027 - mae: 11.7027\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.4062 - mae: 30.4062\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.5557 - mae: 7.5557\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9905 - mae: 15.9905\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.5579 - mae: 8.5579\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.7339 - mae: 28.7339\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.1689 - mae: 13.1689\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.3101 - mae: 18.3101\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7376 - mae: 13.7376\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7104 - mae: 13.7104\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 28.5842 - mae: 28.5842\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0707 - mae: 7.0707\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0550 - mae: 7.0550\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.0067 - mae: 22.0067\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.8443 - mae: 20.8443\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.4713 - mae: 12.4713\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9099 - mae: 17.9099\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.7494 - mae: 13.7494\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.4687 - mae: 5.4687\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7006 - mae: 13.7006\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4142 - mae: 9.4142\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.9796 - mae: 20.9796\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5470 - mae: 9.5470\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7256 - mae: 11.7256\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.3772 - mae: 14.3772\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8579 - mae: 14.8579\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9706 - mae: 14.9706\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8998 - mae: 17.8998\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8327 - mae: 9.8327\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.3352 - mae: 18.3352\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0383 - mae: 15.0383\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5874 - mae: 14.5874\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.3015 - mae: 23.3015\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.3613 - mae: 13.3613\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8517 - mae: 9.8517\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.5451 - mae: 12.5451\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.9472 - mae: 4.9472\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1130 - mae: 7.1130\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 35.4567 - mae: 35.4567\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.8634 - mae: 34.8634\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9846 - mae: 7.9846\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.7004 - mae: 14.7004\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.7196 - mae: 16.7196\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.9329 - mae: 15.9329\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1644 - mae: 16.1644\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.9324 - mae: 13.9324\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.0504 - mae: 18.0504\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.6120 - mae: 15.6120\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.2041 - mae: 21.2041\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2732 - mae: 25.2732\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3176 - mae: 16.3176\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2729 - mae: 7.2729\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9688 - mae: 16.9688\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1225 - mae: 7.1225\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2058 - mae: 9.2058\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.0961 - mae: 8.0961\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.0538 - mae: 17.0538\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8627 - mae: 8.8627\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1711 - mae: 13.1711\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7886 - mae: 8.7886\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.8161 - mae: 18.8161\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.0531 - mae: 14.0531\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6831 - mae: 14.6831\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8045 - mae: 15.8045\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.6810 - mae: 17.6810\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.2367 - mae: 13.2367\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5070 - mae: 14.5070\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.2322 - mae: 23.2322\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3009 - mae: 9.3009\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 36.6569 - mae: 36.6569\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.8205 - mae: 21.8205\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2792 - mae: 7.2792\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.7127 - mae: 24.7127\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4220 - mae: 12.4220\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.5823 - mae: 10.5823\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.4883 - mae: 14.4883\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6132 - mae: 8.6132\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 43.0580 - mae: 43.0580\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4611 - mae: 18.4611\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.8820 - mae: 6.8820\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7211 - mae: 13.7211\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.0154 - mae: 21.0154\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.3731 - mae: 19.3731\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4735 - mae: 11.4735\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.5302 - mae: 7.5302\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.6453 - mae: 21.6453\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 33.1785 - mae: 33.1785\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0833 - mae: 10.0833\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1012 - mae: 12.1012\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.1372 - mae: 26.1372\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1751 - mae: 12.1751\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3272 - mae: 13.3272\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.3775 - mae: 29.3775\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.3329 - mae: 7.3329\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.1362 - mae: 31.1362\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.3015 - mae: 12.3015\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4103 - mae: 16.4103\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.9118 - mae: 21.9118\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.1501 - mae: 22.1501\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7429 - mae: 7.7429\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1429 - mae: 8.1429\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.9435 - mae: 24.9435\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6958 - mae: 13.6958\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.8926 - mae: 6.8926\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.5352 - mae: 24.5352\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.1721 - mae: 20.1721\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.9658 - mae: 11.9658\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.5391 - mae: 16.5391\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.8017 - mae: 16.8017\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.2711 - mae: 15.2711\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.7179 - mae: 22.7179\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9234 - mae: 17.9234\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9440 - mae: 10.9440\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.1530 - mae: 23.1530\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7331 - mae: 17.7331\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.9824 - mae: 6.9824\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.1857 - mae: 25.1857\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9025 - mae: 8.9025\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7668 - mae: 17.7668\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0002 - mae: 11.0002\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.9191 - mae: 12.9191\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4033 - mae: 8.4033\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.6094 - mae: 13.6094\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4404 - mae: 7.4404\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7099 - mae: 10.7099\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.2814 - mae: 13.2814\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.9763 - mae: 29.9763\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6304 - mae: 7.6304\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9106 - mae: 9.9106\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.7669 - mae: 23.7669\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3937 - mae: 16.3937\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.0758 - mae: 21.0758\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9367 - mae: 7.9367\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9731 - mae: 17.9731\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2375 - mae: 10.2375\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3338 - mae: 8.3338\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0621 - mae: 5.0621\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.5109 - mae: 23.5109\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.8309 - mae: 6.8309\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3863 - mae: 16.3863\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5019 - mae: 7.5019\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.0573 - mae: 20.0573\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.7661 - mae: 13.7661\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.8282 - mae: 16.8282\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0514 - mae: 7.0514\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.4846 - mae: 21.4846\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12.2880 - mae: 12.2880\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8117 - mae: 11.8117\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3600 - mae: 8.3600\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4833 - mae: 12.4833\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 32.2171 - mae: 32.2171\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4477 - mae: 10.4477\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.6832 - mae: 19.6832\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 35.0762 - mae: 35.0762\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4192 - mae: 10.4192\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7625 - mae: 9.7625\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9500 - mae: 11.9500\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3943 - mae: 9.3943\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6071 - mae: 5.6071\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 37.4876 - mae: 37.4876\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.8830 - mae: 16.8830\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.8748 - mae: 12.8748\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.1960 - mae: 8.1960\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.5568 - mae: 13.5568\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.4354 - mae: 15.4354\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.9626 - mae: 32.9626\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.2040 - mae: 14.2040\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9196 - mae: 15.9196\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.0878 - mae: 19.0878\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 34.1178 - mae: 34.1178\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6798 - mae: 7.6798\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.2287 - mae: 25.2287\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.6759 - mae: 22.6759\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8765 - mae: 8.8765\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.4709 - mae: 21.4709\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.6073 - mae: 20.6073\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0611 - mae: 7.0611\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.8117 - mae: 25.8117\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.2247 - mae: 32.2247\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0204 - mae: 10.0204\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.4171 - mae: 30.4171\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.5020 - mae: 10.5020\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.9909 - mae: 14.9909\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.6580 - mae: 14.6580\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.3672 - mae: 23.3672\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1025 - mae: 13.1025\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2586 - mae: 9.2586\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6648 - mae: 9.6648\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 13.0041 - mae: 13.0041\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.8863 - mae: 14.8863\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.7932 - mae: 14.7932\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.2751 - mae: 16.2751\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.8307 - mae: 20.8307\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 33.5317 - mae: 33.5317\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.2166 - mae: 8.2166\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0960 - mae: 13.0960\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.3999 - mae: 8.3999\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.1283 - mae: 7.1283\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.9390 - mae: 10.9390\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.7654 - mae: 19.7654\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.8625 - mae: 24.8625\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7422 - mae: 8.7422\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9488 - mae: 5.9488\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.4400 - mae: 24.4400\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.9771 - mae: 5.9771\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3250 - mae: 16.3250\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0917 - mae: 6.0917\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0963 - mae: 11.0963\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.9601 - mae: 14.9601\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6462 - mae: 7.6462\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7654 - mae: 8.7654\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5991 - mae: 14.5991\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.3166 - mae: 11.3166\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.9080 - mae: 21.9080\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8653 - mae: 14.8653\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4970 - mae: 8.4970\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3957 - mae: 10.3957\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.3392 - mae: 6.3392\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4602 - mae: 17.4602\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4627 - mae: 11.4627\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.7294 - mae: 20.7294\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.3338 - mae: 31.3338\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2542 - mae: 9.2542\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.8621 - mae: 14.8621\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.7182 - mae: 21.7182\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6615 - mae: 12.6615\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0687 - mae: 6.0687\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.2201 - mae: 13.2201\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4244 - mae: 27.4244\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6407 - mae: 10.6407\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8230 - mae: 12.8230\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8836 - mae: 15.8836\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.7510 - mae: 24.7510\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.3753 - mae: 17.3753\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8241 - mae: 7.8241\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.3789 - mae: 25.3789\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1031 - mae: 15.1031\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1643 - mae: 7.1643\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3318 - mae: 20.3318\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.3283 - mae: 6.3283\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.9961 - mae: 12.9961\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7869 - mae: 10.7869\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4007 - mae: 11.4007\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6152 - mae: 10.6152\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4582 - mae: 11.4582\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.3851 - mae: 11.3851\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.3986 - mae: 30.3986\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5052 - mae: 10.5052\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.8810 - mae: 28.8810\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5916 - mae: 8.5916\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.7378 - mae: 12.7378\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.6754 - mae: 33.6754\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.0963 - mae: 15.0963\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 17.4813 - mae: 17.4813\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.3049 - mae: 22.3049\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.5841 - mae: 23.5841\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0008 - mae: 11.0008\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9175 - mae: 14.9175\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9979 - mae: 17.9979\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.4482 - mae: 5.4482\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0527 - mae: 10.0527\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.0052 - mae: 14.0052\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.7782 - mae: 16.7782\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.2937 - mae: 14.2937\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.6193 - mae: 30.6193\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6541 - mae: 7.6541\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.1428 - mae: 28.1428\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0017 - mae: 8.0017\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3933 - mae: 10.3933\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0242 - mae: 15.0242\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.5653 - mae: 16.5653\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.8566 - mae: 26.8566\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4852 - mae: 12.4852\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 12.4784 - mae: 12.4784\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.3186 - mae: 13.3186\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 29.5524 - mae: 29.5524\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4664 - mae: 3.4664\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2136 - mae: 15.2136\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.8327 - mae: 20.8327\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.5108 - mae: 30.5108\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0597 - mae: 11.0597\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.8372 - mae: 12.8372\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2398 - mae: 3.2398\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6964 - mae: 16.6964\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3883 - mae: 13.3883\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.2771 - mae: 15.2771\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.7448 - mae: 11.7448\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4113 - mae: 16.4113\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8785 - mae: 13.8785\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 30.6702 - mae: 30.6702\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5880 - mae: 8.5880\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7384 - mae: 10.7384\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9051 - mae: 17.9051\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8095 - mae: 15.8095\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.3054 - mae: 21.3054\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.3845 - mae: 25.3845\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.9815 - mae: 23.9815\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.7734 - mae: 5.7734\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.0010 - mae: 20.0010\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.0419 - mae: 14.0419\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.6088 - mae: 30.6088\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9409 - mae: 11.9409\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7352 - mae: 12.7352\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.6139 - mae: 23.6139\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.5365 - mae: 20.5365\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9942 - mae: 4.9942\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7986 - mae: 12.7986\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3772 - mae: 13.3772\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6727 - mae: 12.6727\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.6192 - mae: 17.6192\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.5629 - mae: 23.5629\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3755 - mae: 9.3755\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6316 - mae: 14.6316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd561f2950>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "EcXharbRt1LI",
        "outputId": "d04fa060-1fe6-41ca-c729-d9cecfb9c066"
      },
      "source": [
        "# Make and plot predictions for model_3\n",
        "y_pred_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_pred_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RUeia6viuc"
      },
      "source": [
        "Strange, we trained for longer but our model performed worse?\n",
        "\n",
        "As it turns out, our model might've trained too long and has thus resulted in worse results (we'll see ways to prevent training for too long later on)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV3KAxivuEq7",
        "outputId": "447ed5e1-1be2-4ff7-cb3b-e7c959f30a90"
      },
      "source": [
        "# Calculate model_3 metrics\n",
        "mae_3 = mae(y_test, y_pred_3)\n",
        "mse_3 = mse(y_test, y_pred_3)\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68.713615, 4808.0273)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAUQbjM1vuAV"
      },
      "source": [
        "## Comparing results\n",
        "\n",
        "Now we've got results for 3 similar but slightly different results, let's compare them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gyFCjJ8sujKF",
        "outputId": "1be540b7-eab8-44fa-9ccd-b746d38fff4a"
      },
      "source": [
        "# Create a list of lists of model results\n",
        "model_results = [['model_1', mae_1, mse_1],\n",
        "                 ['model_2', mae_2, mse_2],\n",
        "                 ['model_3', mae_3, mse_3]]\n",
        "\n",
        "# Covert all models results into Pandas DataFrame\n",
        "all_results = pd.DataFrame(model_results, columns=['model', 'mae', 'mse'])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7BEhyor0Z2k"
      },
      "source": [
        "From our experiments, it looks like `model_2` performed the best.\n",
        "\n",
        "And now, you might be thinking, \"wow, comparing models is tedious...\" and it definitely can be, we've only compared 3 models here. \n",
        "\n",
        "But this is part of what machine learning modelling is about, trying many different combinations of models and seeing which performs best.\n",
        "\n",
        "Each model you build is a small experiment. \n",
        "\n",
        "> ðŸ”‘ **Note:** One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practitioner's motto: \"experiment\".\n",
        "\n",
        "Another thing you'll also find is what you thought may work (such as training a model for longer) may not always work and the exact opposite is also often the case.\n",
        "\n",
        "## Tracking your experiments\n",
        "\n",
        "One really good habit to get into is tracking your modelling experiments to see which perform better than others.\n",
        "\n",
        "We've done a simple version of this above (keeping the results in different variables).\n",
        "\n",
        "> ðŸ“– **Resource:** But as you build more models, you'll want to look into using tools such as:\n",
        "* [**TensorBoard**](https://tensorboard.dev/) - a component of the TensorFlow library to help track modelling experiments (we'll see this later).\n",
        "* [**Weights & Biases**](https://www.wandb.com/) - a tool for tracking all kinds of machine learning experiments (the good news for Weights & Biases is it plugs into TensorBoard)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI8zKsOX0iUw"
      },
      "source": [
        "## Saving a model\n",
        "\n",
        "Once you've trained a model and found one which performs to your liking, you'll probably want to save it for use elsewhere (like a web application or mobile device).\n",
        "\n",
        "You can save a TensorFlow/Keras model using [`model.save()`](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model).\n",
        "\n",
        "There are two ways to save a model in TensorFlow:\n",
        "1. The [SavedModel format](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) (default).\n",
        "2. The [HDF5 format](https://www.tensorflow.org/tutorials/keras/save_and_load#hdf5_format).\n",
        "\n",
        "The main difference between the two is the SavedModel is automatically able to save custom objects (such as special layers) without additional modifications when loading the model back in.\n",
        "\n",
        "Which one should you use?\n",
        "\n",
        "It depends on your situation but the SavedModel format will suffice most of the time.\n",
        "\n",
        "Both methods use the same method call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXyzVSBhyTV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf42db6-2d54-4149-d844-b561c00b9b97"
      },
      "source": [
        "# Save a model using the SavedModel format\n",
        "model_2.save('best_model_SavedModel')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SavedModel/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoFn53lfHckq",
        "outputId": "65f0efc7-5f77-4d02-e2fc-73ecbd1d6796"
      },
      "source": [
        "# Check it out - outputs a protobuf binary file (.pb) as well as other files\n",
        "!ls best_model_SavedModel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4x-PviQICIq"
      },
      "source": [
        "Now let's save the model in the HDF5 format, we'll use the same method but with a different filename."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmusvtUWGRkW"
      },
      "source": [
        "# Save a model using the HDF5 format\n",
        "model_2.save('best_model_HDF5.h5')  # note the addition of '.h5' on the end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmgMuuDAGzmi",
        "outputId": "d0e3cbb0-01a3-4703-e4af-4f4d74fce9df"
      },
      "source": [
        "# Check it out\n",
        "!ls best_model_HDF5.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_HDF5.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeeIvoYwIZsg"
      },
      "source": [
        "## Loading a model\n",
        "\n",
        "We can load a saved model using the [`load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) method.\n",
        "\n",
        "Loading a model for the different formats (SavedModel and HDF5) is the same (as long as the pathnames to the particuluar formats are correct)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfk6zaAeIYBu",
        "outputId": "cdea4b4b-0da2-402a-8840-4c871e0492f0"
      },
      "source": [
        "# Load a model from the SavedModel format\n",
        "loaded_SavedModel = tf.keras.models.load_model('best_model_SavedModel')\n",
        "loaded_SavedModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTEFqs-uNq8d",
        "outputId": "fea0e5b8-91a0-4d9a-b11f-a85b07f7344a"
      },
      "source": [
        "# Compare model_2 with the SavedModel version (should return True)\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_preds = loaded_SavedModel.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z39mO42PQCfq"
      },
      "source": [
        "Loading in from the HDF5 is much the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2jhGgnNNwiP",
        "outputId": "1b906709-81f5-4dea-f611-28271ba22069"
      },
      "source": [
        "# Load a model from the HDF5 format\n",
        "loaded_h5_model = tf.keras.models.load_model('best_model_HDF5.h5')\n",
        "loaded_h5_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ95TC8_OR8h",
        "outputId": "d049f980-7cb3-4f46-96f7-b77c45fbc93c"
      },
      "source": [
        "# Compare model_2 with the loaded HDF5 version (should return True)\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "\n",
        "# Compare by taking mae\n",
        "mae(y_test, model_2_preds) == mae(y_test, loaded_h5_model_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3d1iY_BUEE1"
      },
      "source": [
        "## Downloading a model (from Google Colab)\n",
        "\n",
        "Say you wanted to get your model from Google Colab to your local machine, you can do one of the following things:\n",
        "1. Right click on the file in the files pane and click 'download'.\n",
        "2. Use the code below.\n",
        "3. Use the second code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DDpGlMXMPj6w",
        "outputId": "8898303a-4076-4e98-e24f-01e957ac5601"
      },
      "source": [
        "# Download the model (or any file) from Google Colab\n",
        "from google.colab import files\n",
        "files.download('best_model_HDF5.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7b35c021-725a-47af-8c5c-ba32669bd599\", \"best_model_HDF5.h5\", 17040)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESlty6TjTCjs"
      },
      "source": [
        "# Save a file from Googel Colab to Google Drive (requires mounting Google Drive)\n",
        "!cp /content/best_model_HDF5.h5 /content/drive/MyDrive/saved-models-folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHkdGxqqTO3c",
        "outputId": "63a75a78-80b3-4e23-81dc-f2f9db434ff5"
      },
      "source": [
        "# Check if the file is stored in the given path\n",
        "!ls /content/drive/MyDrive/saved-models-folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_HDF5.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o0tfrsWU24l"
      },
      "source": [
        "## A larger example\n",
        "\n",
        "We've seen the fundamentals of building neural network regression models in TensorFlow.\n",
        "\n",
        "Let's step it up a notch and build a model for a more feature rich dataset.\n",
        "\n",
        "More specifically we're going to try predict the cost of medical insurance for individuals based on a number of different parameters such as, `age`, `sex`, `bmi`, `children`, `smoking_status` and `residential_region`.\n",
        "\n",
        "To do, we'll leverage the pubically available [Medical Cost dataset](https://www.kaggle.com/mirichoi0218/insurance) available from Kaggle and [hosted on GitHub](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv).\n",
        "\n",
        "> ðŸ”‘ **Note:** When learning machine learning paradigms, you'll often go through a series of foundational techniques and then practice them by working with open-source datasets and examples. Just as we're doing now, learn foundations, put them to work with different problems. Every time you work on something new, it's a good idea to search for something like \"problem X example with Python/TensorFlow\" where you substitute X for your problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVv5XiHWTS-f"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJc_dobqWu1T"
      },
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CwEBRn4Kifk8",
        "outputId": "6692d917-3e5a-4a16-b614-f4961f8b1ac6"
      },
      "source": [
        "# Check out the insurance dataset\n",
        "insurance.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJaQivsgilwC"
      },
      "source": [
        "We're going to have to turn the non-numerical columns into numbers (because a neural network can't handle non-numerical inputs).\n",
        "\n",
        "To do so, we'll use the [`get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) method in pandas.\n",
        "\n",
        "It converts categorical variables (like the `sex`, `smoker` and `region` columns) into numerical variables using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "xfp9i5Y4W2Cd",
        "outputId": "bb440d46-a553-456e-a6e4-60367f38559b"
      },
      "source": [
        "# Turn all categories into numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()  # view the converted columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLnW-xyFndcY"
      },
      "source": [
        "Now we'll split data into features (`X`) and labels (`y`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EQTIDjFYZvL"
      },
      "source": [
        "# Create X & y values\n",
        "X = insurance_one_hot.drop('charges', axis=1)\n",
        "y = insurance_one_hot['charges']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "1TOT1Wpoj6mV",
        "outputId": "42391a53-c48d-477f-cb85-941b115a5a59"
      },
      "source": [
        "# View features\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa2CHClHnosL"
      },
      "source": [
        "And create training and test sets. We could do this manually, but to make it easier, we'll leverage the already available [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function available from Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1534j64ukEry"
      },
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKUO4hfcn6aM"
      },
      "source": [
        "Now we can build and fit a model (we'll make it the same as `model_2`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBihkfXnk_KV",
        "outputId": "66bd3de0-084d-4e84-8879-d1b49a6be461"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new mdoel (same as model_2)\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                                       tf.keras.layers.Dense(10),\n",
        "                                       tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7886.7759 - mae: 7886.7759\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7558.1470 - mae: 7558.1470\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7792.0220 - mae: 7792.0220\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.3887 - mae: 7748.3887\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.3940 - mae: 7595.3940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7589.9844 - mae: 7589.9844\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7698.5576 - mae: 7698.5576\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.7778 - mae: 7496.7778\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7493.1743 - mae: 7493.1743\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7769.7295 - mae: 7769.7295\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7706.9028 - mae: 7706.9028\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7687.7231 - mae: 7687.7231\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.9004 - mae: 7689.9004\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7393.5327 - mae: 7393.5327\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.6987 - mae: 7780.6987\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.5098 - mae: 7578.5098\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 985us/step - loss: 7750.8354 - mae: 7750.8354\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7739.2144 - mae: 7739.2144\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 981us/step - loss: 7875.0654 - mae: 7875.0654\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7466.6768 - mae: 7466.6768\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7941.2329 - mae: 7941.2329\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7640.2725 - mae: 7640.2725\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.2671 - mae: 7539.2671\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7619.9653 - mae: 7619.9653\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.1719 - mae: 7644.1719\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7709.0371 - mae: 7709.0371\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7366.8662 - mae: 7366.8662\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7444.3154 - mae: 7444.3154\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.4077 - mae: 7616.4077\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7686.3853 - mae: 7686.3853\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.0977 - mae: 7548.0977\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7501.5532 - mae: 7501.5532\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7363.4160 - mae: 7363.4160\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7295.4478 - mae: 7295.4478\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.8813 - mae: 7569.8813\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.1997 - mae: 7548.1997\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7424.3975 - mae: 7424.3975\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7529.7734 - mae: 7529.7734\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.3232 - mae: 7467.3232\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7635.9292 - mae: 7635.9292\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7536.8398 - mae: 7536.8398\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.5859 - mae: 7616.5859\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7439.4941 - mae: 7439.4941\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 971us/step - loss: 7538.0151 - mae: 7538.0151\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 989us/step - loss: 7415.1470 - mae: 7415.1470\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7420.6938 - mae: 7420.6938\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 999us/step - loss: 7509.9839 - mae: 7509.9839\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7541.1133 - mae: 7541.1133\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.8643 - mae: 7467.8643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7389.3560 - mae: 7389.3560\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7499.7749 - mae: 7499.7749\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.9282 - mae: 7523.9282\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7243.3115 - mae: 7243.3115\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7429.5864 - mae: 7429.5864\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.3999 - mae: 7313.3999\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7526.3877 - mae: 7526.3877\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7542.2666 - mae: 7542.2666\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7576.9277 - mae: 7576.9277\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7546.4048 - mae: 7546.4048\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7351.2261 - mae: 7351.2261\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7302.1436 - mae: 7302.1436\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.0879 - mae: 7393.0879\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.2881 - mae: 7442.2881\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 989us/step - loss: 7492.6782 - mae: 7492.6782\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 975us/step - loss: 7561.9165 - mae: 7561.9165\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 996us/step - loss: 7340.5137 - mae: 7340.5137\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.0845 - mae: 7496.0845\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7617.0303 - mae: 7617.0303\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7641.1948 - mae: 7641.1948\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.2744 - mae: 7084.2744\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7240.4902 - mae: 7240.4902\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7283.4888 - mae: 7283.4888\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.5083 - mae: 7335.5083\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.6392 - mae: 7275.6392\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.1860 - mae: 7313.1860\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7485.7588 - mae: 7485.7588\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7352.2803 - mae: 7352.2803\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7520.5703 - mae: 7520.5703\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7279.3779 - mae: 7279.3779\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7273.8477 - mae: 7273.8477\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7176.5215 - mae: 7176.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7425.6289 - mae: 7425.6289\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.1294 - mae: 7403.1294\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.7271 - mae: 7484.7271\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7217.6074 - mae: 7217.6074\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7134.1562 - mae: 7134.1562\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7083.4360 - mae: 7083.4360\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7254.1782 - mae: 7254.1782\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7268.7456 - mae: 7268.7456\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7470.5220 - mae: 7470.5220\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7210.9536 - mae: 7210.9536\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7395.6816 - mae: 7395.6816\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7328.0884 - mae: 7328.0884\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7230.4380 - mae: 7230.4380\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.3936 - mae: 7261.3936\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7342.5684 - mae: 7342.5684\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 959us/step - loss: 7106.1714 - mae: 7106.1714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcfe2e2450>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAiTXQ2Mlyup",
        "outputId": "c3c07a2f-280b-469e-9ce6-3fc3b14c14c0"
      },
      "source": [
        "# Check the results of the insurance model\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-JNpDrUoNDD"
      },
      "source": [
        "Our model didn't perform very well, let's try a bigger model.\n",
        "\n",
        "We'll try 3 things:\n",
        "- Increasing the number of layers (2 -> 3).\n",
        "- Increasing the number of units in each layer (except for the output layer).\n",
        "- Changing the optimizer (from SGD to Adam).\n",
        "\n",
        "Everything else will stay the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnpda8SOo873"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Add an extra layer and increase number of units\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "                                         tf.keras.layers.Dense(100),  # 100 units\n",
        "                                         tf.keras.layers.Dense(10),  # 10 units\n",
        "                                         tf.keras.layers.Dense(1)  # 1 unit (important for output layer)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model and save the history (we can plot this)\n",
        "history = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_ik5-jBp0qa",
        "outputId": "e51ab752-c0ed-4f82-d678-474bcfa4e9ba"
      },
      "source": [
        "# Evaluate our larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJUTngzovJNU"
      },
      "source": [
        "Much better! Using a larger model and the Adam optimizer results in almost half the error as the previous model.\n",
        "\n",
        "> ðŸ”‘ **Note:** For many problems, the [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) is a great starting choice. See Andrei Karpathy's \"Adam is safe\" point from [*A Recipe for Training Neural Networks*](http://karpathy.github.io/2019/04/25/recipe/) for more. \n",
        "\n",
        "Let's check out the loss curves of our model, we should see a downward trend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ljxsHnTgrq3p",
        "outputId": "99f2927a-e460-4886-dc1d-e592c2e89ca4"
      },
      "source": [
        "# Plot history (also known as a loss curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzReCqtxtG-B"
      },
      "source": [
        "From this, it looks like our model's loss (and MAE) were both still decreasing (in our case, MAE and loss are the same, hence the lines in the plot overlap eachother).\n",
        "\n",
        "What this tells us is the loss might go down if we try training it for longer.\n",
        "\n",
        "> ðŸ¤” **Question:** How long should you train for? \n",
        "\n",
        "> It depends on what problem you're working on. Sometimes training won't take very long, other times it'll take longer than you expect. A common method is to set your model training for a very long time (e.g. 1000's of epochs) but set it up with an [EarlyStopping callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) so it stops automatically when it stops improving. We'll see this in another module.\n",
        "\n",
        "Let's train the same model as above for a little longer. We can do this but calling fit on it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZXdQ7LMvmDP"
      },
      "source": [
        "# Try to training for a little longer (100 more epochs)\n",
        "history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abAeFmeA0uVz"
      },
      "source": [
        "How did the extra training go?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDy5otgo0tUf",
        "outputId": "d8c848c1-bf24-4b64-9358-58ae6ec987f0"
      },
      "source": [
        "# Evaluate the model trained for 200 total epochs\n",
        "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, y_test, verbose=0)\n",
        "insurance_model_2_loss, insurance_model_2_mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3494.728515625, 3494.728515625)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCqbiZq41J2l"
      },
      "source": [
        "Training for an extra 100 epochs we see about a 10% decrease in error.\n",
        "\n",
        "How does the visual look?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Lk2L6LqA1H0y",
        "outputId": "307649ba-d8c8-4452-d6f9-ad776189dd4f"
      },
      "source": [
        "# Plot the model trained for 200 total epochs loss curves\n",
        "pd.DataFrame(history_2.history).plot()\n",
        "plt.xlabel('epochs')  # note: epochs will only show 100 since we overrid the history variable\n",
        "plt.ylabel('loss');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzbuo_5O1raY"
      },
      "source": [
        "## Preprocessing data (normalization and standardization)\n",
        "\n",
        "A common practice when working with neural networks is to make sure all of the data you pass to them is in the range 0 to 1.\n",
        "\n",
        "This practice is called **normalization** (scaling all values from their original range to, e.g. between 0 and 100,000 to be between 0 and 1).\n",
        "\n",
        "There is another process call **standardization** which converts all of your data to unit variance and 0 mean.\n",
        "\n",
        "These two practices are often part of a preprocessing pipeline (a series of functions to prepare your data for use with neural networks).\n",
        "\n",
        "Knowing this, some of the major steps you'll take to preprocess your data for a neural network include:\n",
        "* Turning all of your data to numbers (a neural network can't handle strings).\n",
        "* Making sure your data is in the right shape (verifying input and output shapes).\n",
        "* [**Feature scaling**](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler):\n",
        "    * Normalizing data (making sure all values are between 0 and 1). This is done by subtracting the minimum value then dividing by the maximum value minus the minimum. This is also referred to as min-max scaling.\n",
        "    * Standardization (making sure all values have a mean of 0 and a variance of 1). This is done by substracting the mean value from the target feature and then dividing it by the standard deviation.\n",
        "    * Which one should you use?\n",
        "      * **With neural networks you'll tend to favour normalization** as they tend to prefer values between 0 and 1 (you'll see this espcially with image processing), however, you'll often find a neural network can perform pretty well with minimal feature scaling.\n",
        "\n",
        "> ðŸ“– **Resource:** For more on preprocessing data, I'd recommend reading the following resources:\n",
        "* [Scikit-Learn's documentation on preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data).\n",
        "* [Scale, Standardize or Normalize with Scikit-Learn by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02).\n",
        "\n",
        "We've already turned our data into numbers using `get_dummies()`, let's see how we'd normalize it as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qkxpVcOF3-S3",
        "outputId": "26773a41-a71e-4d16-e864-f68d7b6377c1"
      },
      "source": [
        "# Call our dataset again\n",
        "insurance.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylQZTv6u28RA"
      },
      "source": [
        "Now, just as before, we need to transform the non-numerical columns into numbers and this time we'll also be normalizing the numerical columns with different ranges (to make sure they're all between 0 and 1).\n",
        "\n",
        "To do this, we're going to use a few classes from Scikit-Learn:\n",
        "* [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) - build a multi-step data preprocessing function for the folllowing trnasformations:\n",
        "  * [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - make sure all numerical columns are normalized (between 0 and 1).\n",
        "  * [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) - one hot encode the non-numerical columns.\n",
        "\n",
        "Let's see them in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBGUXetJ2_qq"
      },
      "source": [
        "# Import sklearn libraries for column transformation, normalization, and for one-hot encode\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), ['age', 'bmi', 'children']),  # turn all values in these columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['sex', 'smoker', 'region'])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop('charges', axis=1)\n",
        "y = insurance['charges']\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would in data leakage)\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and one hot encoding (OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF1VWR94DRvl"
      },
      "source": [
        "Now we've normalized it and one-hot encoding it, what does our data look like now?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUYC-YIKBEhf",
        "outputId": "12c78e3e-897a-4455-a3f7-93ad8a8e9d14"
      },
      "source": [
        "# Non-normalized and non-one-hot encoded data example\n",
        "X_train.loc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu9hptdsBOJm",
        "outputId": "196d7697-7960-4cfc-8740-d9cb73bf5c84"
      },
      "source": [
        "# Normalized and one-hot encoded example\n",
        "X_train_normal[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOp4r1dnDhd4"
      },
      "source": [
        "How about the shapes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9jhCAh6BX3U",
        "outputId": "cad71d34-4a52-4757-abb3-8dd1642793bc"
      },
      "source": [
        "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKnV7hMpDxJ4"
      },
      "source": [
        "Our data is normalized and numerical, let's model it.\n",
        "\n",
        "We'll use the same model as `insurance_model_2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4BWa_aFBmPB"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "                                         tf.keras.layers.Dense(100),\n",
        "                                         tf.keras.layers.Dense(10),\n",
        "                                         tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model for 200 epochs (same as insurance_model_2)\n",
        "history_3 = insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALywaoBYSTJq",
        "outputId": "d20afa17-ff80-4cec-8213-6d82b1995708"
      },
      "source": [
        "# Evaluate 3rd model\n",
        "insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 3171.5774 - mae: 3171.5774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoTPRj4RVb1H"
      },
      "source": [
        "How does it look visually?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Fv13wRPzUe7e",
        "outputId": "d235c249-0720-4fc5-fade-b794b0a3d955"
      },
      "source": [
        "# Plot the model to view the loss curve\n",
        "pd.DataFrame(history_3.history).plot()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfuGx-0NUPFb"
      },
      "source": [
        "And finally, let's compare the results from `insurance_model_2` (trained on non-normalized data) and `insurance_model_3` (trained on normalized data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOcnljScSbf6",
        "outputId": "8e014bbd-e0b7-42fe-8c01-26a4625f3bc3"
      },
      "source": [
        "# Compare modelling results fron non-normalized data and normalized data\n",
        "insurance_model_2_mae, insurance_model_3_mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3494.728515625, 3171.577392578125)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzM2ACqyV3WW"
      },
      "source": [
        "From this we can see normalizing the data results in 10% less error using the same model than not normalizing the data.\n",
        "\n",
        "This is **one of the main benefits of normalization: faster convergence time** (a fancy way of saying, your model gets to better results faster).\n",
        "\n",
        "`insurance_model_2` may have eventually achieved the same results as `insurance_model_3` if we left it training for longer. \n",
        "\n",
        "Also, the results may change if we were to alter the architectures of the models, e.g. more hidden units per layer or more layers.\n",
        "\n",
        "But since our main goal as neural network practioners is to decrease the time between experiments, anything that helps us get better results sooner is a plus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHLrfu3coGjd"
      },
      "source": [
        "## ðŸ›  Exercises\n",
        "\n",
        "We've a covered a whole lot pretty quickly.\n",
        "\n",
        "So now it's time to have a **play around** with a few things and start to build up your initution.\n",
        "\n",
        "I emphasise the words play around because that's very important. Try a few things out, run the code and see what happens.\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "  * Building a larger model (how does one with 4 dense layers go?).\n",
        "  * Increasing the number of units in each layer.\n",
        "  * Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "  * What happens if you train for longer (say 300 epochs instead of 200)? \n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uruHfhmIoK_R"
      },
      "source": [
        "## ðŸ“– Extra curriculum\n",
        "\n",
        "If you're looking for extra materials relating to this notebook, I'd check out the following:\n",
        "\n",
        "* [MIT introduction deep learning lecture 1](https://youtu.be/njKP3FqW3Sk) - gives a great overview of what's happening behind all of the code we're running.\n",
        "* Reading: 1-hour of [Chapter 1 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.\n",
        "\n",
        "To practice your regression modelling with TensorFlow, I'd also encourage you to look through [Lion Bridge's collection of datasets](https://lionbridge.ai/datasets/) or [Kaggle's datasets](https://www.kaggle.com/data), find a regression dataset which sparks your interest and try to model."
      ]
    }
  ]
}