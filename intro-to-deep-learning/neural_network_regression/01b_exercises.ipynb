{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01b_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PL3fw7_n2aSnHlF6N25Qyr-CwfaEuww3",
      "authorship_tag": "ABX9TyMJHdUvhOpZyRmO/O85LU3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadAwon/backyard-projects/blob/main/intro-to-deep-learning/neural_network_regression/01b_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbxNUlo0zM8o"
      },
      "source": [
        "## ðŸ“– Extra curriculum\n",
        "\n",
        "If you're looking for extra materials relating to this notebook, I'd check out the following:\n",
        "\n",
        "* [MIT introduction deep learning lecture 1](https://youtu.be/njKP3FqW3Sk) - gives a great overview of what's happening behind all of the code we're running.\n",
        "* Reading: 1-hour of [Chapter 1 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.\n",
        "\n",
        "To practice your regression modelling with TensorFlow, I'd also encourage you to look through [Lion Bridge's collection of datasets](https://lionbridge.ai/datasets/) or [Kaggle's datasets](https://www.kaggle.com/data), find a regression dataset which sparks your interest and try to model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezMi1VCGBcPX"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwRbnIVDJlD"
      },
      "source": [
        "The table below represents weekly 2018 retail scan data for National retail volume (units) and price. Retail scan data comes directly from retailersâ€™ cash registers based on actual retail sales of Hass avocados. Starting in 2013, the table below reflects an expanded, multi-outlet retail data set. Multi-outlet reporting includes an aggregation of the following channels: grocery, mass, club, drug, dollar and military. The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. The Product Lookup codes (PLUâ€™s) in the table are only for Hass avocados. Other varieties of avocados (e.g. greenskins) are not included in this table.\n",
        "\n",
        "Some relevant columns in the dataset:\n",
        "\n",
        "* `AveragePrice` - the average price of a single avocado\n",
        "* `type` - conventional or organic\n",
        "* `year` - the year\n",
        "* `Region` - the city or region of the observation\n",
        "* `Total Volume` - Total number of avocados sold\n",
        "* `4046` - Total number of avocados with PLU 4046 sold (**non-organic small/medium Hass Avocados ~3-5 oz**)\n",
        "* `4225` - Total number of avocados with PLU 4225 sold (**non-organic large Hass Avocados ~8-10 oz**)\n",
        "* `4770` - Total number of avocados with PLU 4770 sold (**non-organic extra large Hass Avocados ~10-15 oz**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Vxvp-OmSB1de",
        "outputId": "091ee9be-7c67-46be-b806-f8ee3b63bc2c"
      },
      "source": [
        "# Import dataset\n",
        "avocado = pd.read_csv('Avocado.csv')\n",
        "avocado.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>4046</th>\n",
              "      <th>4225</th>\n",
              "      <th>4770</th>\n",
              "      <th>Total Volume</th>\n",
              "      <th>Small Bags</th>\n",
              "      <th>Large Bags</th>\n",
              "      <th>XLarge Bags</th>\n",
              "      <th>Total Bags</th>\n",
              "      <th>AveragePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>1036.74</td>\n",
              "      <td>54454.85</td>\n",
              "      <td>48.16</td>\n",
              "      <td>64236.62</td>\n",
              "      <td>8603.62</td>\n",
              "      <td>93.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8696.87</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>674.28</td>\n",
              "      <td>44638.81</td>\n",
              "      <td>58.33</td>\n",
              "      <td>54876.98</td>\n",
              "      <td>9408.07</td>\n",
              "      <td>97.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9505.56</td>\n",
              "      <td>1.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>794.70</td>\n",
              "      <td>109149.67</td>\n",
              "      <td>130.50</td>\n",
              "      <td>118220.22</td>\n",
              "      <td>8042.21</td>\n",
              "      <td>103.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8145.35</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>1132.00</td>\n",
              "      <td>71976.41</td>\n",
              "      <td>72.58</td>\n",
              "      <td>78992.15</td>\n",
              "      <td>5677.40</td>\n",
              "      <td>133.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5811.16</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>941.48</td>\n",
              "      <td>43838.39</td>\n",
              "      <td>75.78</td>\n",
              "      <td>51039.60</td>\n",
              "      <td>5986.26</td>\n",
              "      <td>197.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6183.95</td>\n",
              "      <td>1.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   region          type  year  ...  XLarge Bags  Total Bags  AveragePrice\n",
              "0  Albany  conventional  2015  ...          0.0     8696.87          1.33\n",
              "1  Albany  conventional  2015  ...          0.0     9505.56          1.35\n",
              "2  Albany  conventional  2015  ...          0.0     8145.35          0.93\n",
              "3  Albany  conventional  2015  ...          0.0     5811.16          1.08\n",
              "4  Albany  conventional  2015  ...          0.0     6183.95          1.28\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKy51aOkHN6i",
        "outputId": "49df9668-7038-4de0-871f-4fd7c61c59a6"
      },
      "source": [
        "avocado.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18249, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1Meq48CCExk",
        "outputId": "acab3005-c529-47f5-e772-5959605bfed9"
      },
      "source": [
        "# Find null values\n",
        "avocado.isnull().any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region          False\n",
              "type            False\n",
              "year            False\n",
              "4046            False\n",
              "4225            False\n",
              "4770            False\n",
              "Total Volume    False\n",
              "Small Bags      False\n",
              "Large Bags      False\n",
              "XLarge Bags     False\n",
              "Total Bags      False\n",
              "AveragePrice    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6elBpH3HL22",
        "outputId": "43fcc51d-ca57-40ec-e5ec-c3c796d83a6b"
      },
      "source": [
        "# Columns information\n",
        "avocado.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18249 entries, 0 to 18248\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   region        18249 non-null  object \n",
            " 1   type          18249 non-null  object \n",
            " 2   year          18249 non-null  int64  \n",
            " 3   4046          18249 non-null  float64\n",
            " 4   4225          18249 non-null  float64\n",
            " 5   4770          18249 non-null  float64\n",
            " 6   Total Volume  18249 non-null  float64\n",
            " 7   Small Bags    18249 non-null  float64\n",
            " 8   Large Bags    18249 non-null  float64\n",
            " 9   XLarge Bags   18249 non-null  float64\n",
            " 10  Total Bags    18249 non-null  float64\n",
            " 11  AveragePrice  18249 non-null  float64\n",
            "dtypes: float64(9), int64(1), object(2)\n",
            "memory usage: 1.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "spsJ3wtlHWy0",
        "outputId": "59381ecd-82d8-4e84-ab51-e3a5b8bbf5a4"
      },
      "source": [
        "# Data statistical summary\n",
        "avocado.describe().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>2016.147899</td>\n",
              "      <td>9.399385e-01</td>\n",
              "      <td>2015.00</td>\n",
              "      <td>2015.00</td>\n",
              "      <td>2016.00</td>\n",
              "      <td>2017.00</td>\n",
              "      <td>2018.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4046</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>293008.424531</td>\n",
              "      <td>1.264989e+06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>854.07</td>\n",
              "      <td>8645.30</td>\n",
              "      <td>111020.20</td>\n",
              "      <td>22743616.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4225</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>295154.568356</td>\n",
              "      <td>1.204120e+06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3008.78</td>\n",
              "      <td>29061.02</td>\n",
              "      <td>150206.86</td>\n",
              "      <td>20470572.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4770</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>22839.735993</td>\n",
              "      <td>1.074641e+05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>184.99</td>\n",
              "      <td>6243.42</td>\n",
              "      <td>2546439.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Volume</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>850644.013009</td>\n",
              "      <td>3.453545e+06</td>\n",
              "      <td>84.56</td>\n",
              "      <td>10838.58</td>\n",
              "      <td>107376.76</td>\n",
              "      <td>432962.29</td>\n",
              "      <td>62505646.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Small Bags</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>182194.686696</td>\n",
              "      <td>7.461785e+05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2849.42</td>\n",
              "      <td>26362.82</td>\n",
              "      <td>83337.67</td>\n",
              "      <td>13384586.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Large Bags</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>54338.088145</td>\n",
              "      <td>2.439660e+05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>127.47</td>\n",
              "      <td>2647.71</td>\n",
              "      <td>22029.25</td>\n",
              "      <td>5719096.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XLarge Bags</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>3106.426507</td>\n",
              "      <td>1.769289e+04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>132.50</td>\n",
              "      <td>551693.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total Bags</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>239639.202060</td>\n",
              "      <td>9.862424e+05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5088.64</td>\n",
              "      <td>39743.83</td>\n",
              "      <td>110783.37</td>\n",
              "      <td>19373134.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AveragePrice</th>\n",
              "      <td>18249.0</td>\n",
              "      <td>1.405978</td>\n",
              "      <td>4.026766e-01</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.66</td>\n",
              "      <td>3.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                count           mean  ...        75%          max\n",
              "year          18249.0    2016.147899  ...    2017.00      2018.00\n",
              "4046          18249.0  293008.424531  ...  111020.20  22743616.17\n",
              "4225          18249.0  295154.568356  ...  150206.86  20470572.61\n",
              "4770          18249.0   22839.735993  ...    6243.42   2546439.11\n",
              "Total Volume  18249.0  850644.013009  ...  432962.29  62505646.52\n",
              "Small Bags    18249.0  182194.686696  ...   83337.67  13384586.80\n",
              "Large Bags    18249.0   54338.088145  ...   22029.25   5719096.61\n",
              "XLarge Bags   18249.0    3106.426507  ...     132.50    551693.65\n",
              "Total Bags    18249.0  239639.202060  ...  110783.37  19373134.37\n",
              "AveragePrice  18249.0       1.405978  ...       1.66         3.25\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qZQvSm8TqD5"
      },
      "source": [
        "X = avocado.drop('AveragePrice', axis=1)\n",
        "y = avocado['AveragePrice']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EKMqI7okT2nw",
        "outputId": "ebb169db-01c2-4b63-f642-601b02f2c8aa"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>4046</th>\n",
              "      <th>4225</th>\n",
              "      <th>4770</th>\n",
              "      <th>Total Volume</th>\n",
              "      <th>Small Bags</th>\n",
              "      <th>Large Bags</th>\n",
              "      <th>XLarge Bags</th>\n",
              "      <th>Total Bags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>1036.74</td>\n",
              "      <td>54454.85</td>\n",
              "      <td>48.16</td>\n",
              "      <td>64236.62</td>\n",
              "      <td>8603.62</td>\n",
              "      <td>93.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8696.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>674.28</td>\n",
              "      <td>44638.81</td>\n",
              "      <td>58.33</td>\n",
              "      <td>54876.98</td>\n",
              "      <td>9408.07</td>\n",
              "      <td>97.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9505.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>794.70</td>\n",
              "      <td>109149.67</td>\n",
              "      <td>130.50</td>\n",
              "      <td>118220.22</td>\n",
              "      <td>8042.21</td>\n",
              "      <td>103.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8145.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>1132.00</td>\n",
              "      <td>71976.41</td>\n",
              "      <td>72.58</td>\n",
              "      <td>78992.15</td>\n",
              "      <td>5677.40</td>\n",
              "      <td>133.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5811.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Albany</td>\n",
              "      <td>conventional</td>\n",
              "      <td>2015</td>\n",
              "      <td>941.48</td>\n",
              "      <td>43838.39</td>\n",
              "      <td>75.78</td>\n",
              "      <td>51039.60</td>\n",
              "      <td>5986.26</td>\n",
              "      <td>197.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6183.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   region          type  year  ...  Large Bags  XLarge Bags  Total Bags\n",
              "0  Albany  conventional  2015  ...       93.25          0.0     8696.87\n",
              "1  Albany  conventional  2015  ...       97.49          0.0     9505.56\n",
              "2  Albany  conventional  2015  ...      103.14          0.0     8145.35\n",
              "3  Albany  conventional  2015  ...      133.76          0.0     5811.16\n",
              "4  Albany  conventional  2015  ...      197.69          0.0     6183.95\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIM-yR0pT9ME",
        "outputId": "4eaeeb08-dcb1-40f9-8804-ed02af7a07a2"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.33\n",
              "1        1.35\n",
              "2        0.93\n",
              "3        1.08\n",
              "4        1.28\n",
              "         ... \n",
              "18244    1.63\n",
              "18245    1.71\n",
              "18246    1.87\n",
              "18247    1.93\n",
              "18248    1.62\n",
              "Name: AveragePrice, Length: 18249, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jbUdHzXUAEF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.2,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J21xOb8Ur76",
        "outputId": "242aab74-7c9f-41a4-fdc6-07023086aa9b"
      },
      "source": [
        "train_features.shape, test_features.shape, train_labels.shape, test_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14599, 11), (3650, 11), (14599,), (3650,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Aa1agwVn8k",
        "outputId": "35b49432-72d7-4911-9d1a-b07fb424bf19"
      },
      "source": [
        "X.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['region', 'type', 'year', '4046', '4225', '4770', 'Total Volume',\n",
              "       'Small Bags', 'Large Bags', 'XLarge Bags', 'Total Bags'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU4Ucl9fUzjq"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), ['year', '4046', '4225', '4770', 'Total Volume',\n",
        "       'Small Bags', 'Large Bags', 'XLarge Bags', 'Total Bags']),\n",
        "       (OneHotEncoder(), ['region', 'type'])\n",
        ")\n",
        "\n",
        "ct.fit(train_features)\n",
        "\n",
        "train_features_norm = ct.transform(train_features)\n",
        "test_features_norm = ct.transform(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9-K8ugwVkUB"
      },
      "source": [
        "train_features_norm = train_features_norm.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwhte0DZWmTI"
      },
      "source": [
        "test_features_norm = test_features_norm.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usFs-nilW0qF",
        "outputId": "99f6e4b6-df10-49d9-f35d-0c21a992bb40"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100),\n",
        "                             tf.keras.layers.Dense(10),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "history = model.fit(train_features_norm, train_labels, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2354 - mae: 0.2354\n",
            "Epoch 2/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.2062 - mae: 0.2062\n",
            "Epoch 3/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.2047 - mae: 0.2047\n",
            "Epoch 4/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2045 - mae: 0.2045\n",
            "Epoch 5/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2037 - mae: 0.2037\n",
            "Epoch 6/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2037 - mae: 0.2037\n",
            "Epoch 7/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2034 - mae: 0.2034\n",
            "Epoch 8/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2032 - mae: 0.2032\n",
            "Epoch 9/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2023 - mae: 0.2023\n",
            "Epoch 10/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2025 - mae: 0.2025\n",
            "Epoch 11/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2024 - mae: 0.2024\n",
            "Epoch 12/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2022 - mae: 0.2022\n",
            "Epoch 13/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2026 - mae: 0.2026\n",
            "Epoch 14/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2027 - mae: 0.2027\n",
            "Epoch 15/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2021 - mae: 0.2021\n",
            "Epoch 16/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2017 - mae: 0.2017\n",
            "Epoch 17/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2022 - mae: 0.2022\n",
            "Epoch 18/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2018 - mae: 0.2018\n",
            "Epoch 19/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.2019 - mae: 0.2019\n",
            "Epoch 20/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2015 - mae: 0.2015\n",
            "Epoch 21/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2014 - mae: 0.2014\n",
            "Epoch 22/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2012 - mae: 0.2012\n",
            "Epoch 23/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2012 - mae: 0.2012\n",
            "Epoch 24/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2007 - mae: 0.2007\n",
            "Epoch 25/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2010 - mae: 0.2010\n",
            "Epoch 26/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2009 - mae: 0.2009\n",
            "Epoch 27/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2010 - mae: 0.2010\n",
            "Epoch 28/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2007 - mae: 0.2007\n",
            "Epoch 29/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2008 - mae: 0.2008\n",
            "Epoch 30/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2008 - mae: 0.2008\n",
            "Epoch 31/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.2005 - mae: 0.2005\n",
            "Epoch 32/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 33/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2007 - mae: 0.2007\n",
            "Epoch 34/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 35/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 36/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 37/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2001 - mae: 0.2001\n",
            "Epoch 38/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2002 - mae: 0.2002\n",
            "Epoch 39/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 40/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2005 - mae: 0.2005\n",
            "Epoch 41/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2002 - mae: 0.2002\n",
            "Epoch 42/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2000 - mae: 0.2000\n",
            "Epoch 43/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 44/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2003 - mae: 0.2003\n",
            "Epoch 45/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2001 - mae: 0.2001\n",
            "Epoch 46/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 47/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1998 - mae: 0.1998\n",
            "Epoch 48/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2000 - mae: 0.2000\n",
            "Epoch 49/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1998 - mae: 0.1998\n",
            "Epoch 50/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 51/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 52/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 53/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1998 - mae: 0.1998\n",
            "Epoch 54/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1999 - mae: 0.1999\n",
            "Epoch 55/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.2000 - mae: 0.2000\n",
            "Epoch 56/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1998 - mae: 0.1998\n",
            "Epoch 57/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1997 - mae: 0.1997\n",
            "Epoch 58/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1997 - mae: 0.1997\n",
            "Epoch 59/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1997 - mae: 0.1997\n",
            "Epoch 60/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1997 - mae: 0.1997\n",
            "Epoch 61/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 62/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 63/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 64/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 65/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 66/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1996 - mae: 0.1996\n",
            "Epoch 67/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 68/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1996 - mae: 0.1996\n",
            "Epoch 69/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 70/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 71/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 72/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 73/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 74/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1996 - mae: 0.1996\n",
            "Epoch 75/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 76/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 77/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 78/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 79/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 80/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 81/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1998 - mae: 0.1998\n",
            "Epoch 82/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 83/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 84/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 85/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 86/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 87/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 88/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 89/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1994 - mae: 0.1994\n",
            "Epoch 90/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 91/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 92/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 93/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 94/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 95/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 96/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 97/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 98/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 99/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 100/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 101/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 102/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 103/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 104/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 105/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 106/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 107/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1995 - mae: 0.1995\n",
            "Epoch 108/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 109/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 110/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 111/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 112/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 113/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 114/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 115/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 116/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 117/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 118/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 119/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 120/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 121/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 122/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 123/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 124/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 125/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 126/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 127/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1993 - mae: 0.1993\n",
            "Epoch 128/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 129/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 130/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 131/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 132/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 133/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 134/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 135/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 136/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 137/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 138/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 139/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 140/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 141/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 142/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 143/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 144/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 145/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 146/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 147/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 148/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 149/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 150/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 151/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 152/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 153/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 154/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 155/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 156/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 157/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 158/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 159/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 160/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 161/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 162/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 163/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 164/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 165/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 166/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 167/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 168/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1991 - mae: 0.1991\n",
            "Epoch 169/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 170/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 171/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 172/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 173/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 174/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 175/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 176/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 177/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 178/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1987 - mae: 0.1987\n",
            "Epoch 179/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 180/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 181/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 182/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 183/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 184/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 185/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 186/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 187/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 188/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 189/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 190/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 191/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 192/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 193/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.1990\n",
            "Epoch 194/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1989 - mae: 0.1989\n",
            "Epoch 195/200\n",
            "457/457 [==============================] - 1s 1ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 196/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 197/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1987 - mae: 0.1987\n",
            "Epoch 198/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 199/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 200/200\n",
            "457/457 [==============================] - 1s 2ms/step - loss: 0.1986 - mae: 0.1986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ieg05hqIYbH7",
        "outputId": "700a3f0c-4665-4799-cdbb-fd8caa397e96"
      },
      "source": [
        "pd.DataFrame(history.history).plot()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufjYp3xua8Qg",
        "outputId": "79312b90-8c36-4a66-ad6f-68177f231b0b"
      },
      "source": [
        "_, mae = model.evaluate(test_features_norm, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 0s 1ms/step - loss: 0.2015 - mae: 0.2015\n"
          ]
        }
      ]
    }
  ]
}