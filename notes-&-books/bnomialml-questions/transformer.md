# The brains behind transformers

It took some time, but Kinsley finished replacing her old model based on a *Long Short-Term Memory (LSTM)* network with a new version using Transformers.

The results of the new model were impressive. The whole team was thrilled with Kinsley's work, and the company organized an internal session for Kinsley to bring everyone up to speed.

After finishing her speech, a coworker asked Kinsley a question:

**Which company invented the Transformer architecture?**

- [ ] Hugging Face
- [ ] OpenAI
- [x] Google
- [ ] Allen Institute of AI

## Answer

In 2017, a team at [Google Brain](https://en.wikipedia.org/wiki/Google_Brain) published the now-famous paper *"Attention Is All You Need,"* where they introduced the Transformer architecture, which transforms one sequence into another with the help of an Encoder and a Decoder.

[Hugging Face](https://huggingface.co/) is an AI community that hosts many NLP models, including a large number of transformer models. Despite being a pioneer in adopting transformer models, Hugging Face is not behind the creation of Transformers.

OpenAI is another powerhouse that conducts AI research to promote and develop AI to benefit humanity. OpenAI is behind models like *GPT-3*, *CLIP*, and *DALL-E*, all of which use the Transformer architecture. OpenAI, however, didn't invent Transformers.

Finally, the *Allen Institute of AI* (also known as AI2) is the AI research institute behind Macaw, a high-performance question-answering model capable of giving GPT-3 a run for its money. Despite their work with Transformers, they aren't behind its creation either.

In summary, the correct answer to this question is that Google is the inventor of Transformers.

## References

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [GPT-3](https://en.wikipedia.org/wiki/GPT-3)
- [CLIP](https://openai.com/blog/clip/)
- [DALL-E](https://openai.com/blog/dall-e/)
- [Macaw](https://macaw.apps.allenai.org/)
